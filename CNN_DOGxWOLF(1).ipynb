{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraPiv/CNN-DogXWolf/blob/main/CNN_DOGxWOLF(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Imports**"
      ],
      "metadata": {
        "id": "m-xkfkjxR928"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK3AUGlM_kYJ"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mJYge5S57tXs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers import Dense, Flatten, Convolution2D, Conv2D, MaxPooling2D,BatchNormalization, Dropout, Activation, AveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import tensorflow as ts\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import kagglehub\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2_qIgn07tXu"
      },
      "source": [
        "#**Reading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HIIvbDi_llN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() #Go to your Kaggle account and create an API token, then upload the saved file from your computer.\n",
        "\n",
        "kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
        "if not os.path.exists(kaggle_dir):\n",
        "    os.makedirs(kaggle_dir)\n",
        "\n",
        "kaggle_file_name = next(iter(uploaded))\n",
        "shutil.move(kaggle_file_name, os.path.join(kaggle_dir, \"kaggle.json\"))\n",
        "\n",
        "os.chmod(os.path.join(kaggle_dir, \"kaggle.json\"), 0o600)\n",
        "\n",
        "!kaggle datasets download -d harishvutukuri/dogs-vs-wolves\n",
        "\n",
        "!unzip -o dogs-vs-wolves.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"harishvutukuri/dogs-vs-wolves\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "zKhZjgAdcXB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/root/.cache/kagglehub/datasets/harishvutukuri/dogs-vs-wolves/versions/2/data'\n",
        "print(\"Directory content 'data':\", os.listdir(data_path))"
      ],
      "metadata": {
        "id": "gBr2ie59eNME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv5vaiqd7tXz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dogs = []\n",
        "wolves = []\n",
        "img_size = 300\n",
        "DOGS_IMGS_PATH = os.path.join(data_path, 'dogs')\n",
        "WOLVES_IMGS_PATH = os.path.join(data_path, 'wolves')\n",
        "DIRS = [(0, DOGS_IMGS_PATH), (1, WOLVES_IMGS_PATH)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc4PtJG87tX0"
      },
      "source": [
        "# **Training Data and Show**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF2Q2CsB7tX3"
      },
      "outputs": [],
      "source": [
        "train_images = []\n",
        "labels = []\n",
        "for num, _dir in DIRS:\n",
        "    _dir = _dir + '/'\n",
        "    count = 0\n",
        "    for file in os.listdir(_dir):\n",
        "        if count >= 1000:\n",
        "            break\n",
        "        img = image.load_img(_dir + str(file), target_size=(img_size, img_size))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img/255\n",
        "        train_images.append(img)\n",
        "        labels.append(num)\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yn9g-P37tX6"
      },
      "outputs": [],
      "source": [
        "train_images[1].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gXO9SUR7tYC"
      },
      "outputs": [],
      "source": [
        "len(train_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j_BqsoT7tYE"
      },
      "outputs": [],
      "source": [
        "X = np.array(train_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5W9bb5P7tYF"
      },
      "source": [
        "# **Training & Testing data for Work**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMBu5UNu7tYG"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDBBBR8S7tYG"
      },
      "outputs": [],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LFhYAPM7tYH"
      },
      "outputs": [],
      "source": [
        "y_train_labels = to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MsJxH7k7tYI"
      },
      "source": [
        "# **Initialize the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2Rhis1G7tYJ"
      },
      "outputs": [],
      "source": [
        "def build(width, height, depth, classes):\n",
        "\n",
        "    model = Sequential()\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        inputShape = (depth, height, width)\n",
        "        chanDim = 1\n",
        "\n",
        "    #Input layer\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=inputShape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # (CONV -> RELU -> POOL)\n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # (CONV -> RELU -> POOL)\n",
        "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # Flatten -> Dense -> RELU\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Camada final\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd4WV8yL7tYK"
      },
      "outputs": [],
      "source": [
        "model = build(img_size,img_size, 3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSD8tMat7tYL"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkGFYTU47tYM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceRZaTdn7tYM"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train_labels, batch_size=32, epochs=15, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Classifying New Photos**\n",
        "\n"
      ],
      "metadata": {
        "id": "PA3e3vWAZw_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jjBs5NI7tYT"
      },
      "outputs": [],
      "source": [
        "input_shape = (300, 300, 3)\n",
        "\n",
        "def load_and_preprocess_image(img_path_or_url):\n",
        "    try:\n",
        "\n",
        "        if img_path_or_url.startswith('http'):\n",
        "            response = requests.get(img_path_or_url)\n",
        "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        else:\n",
        "            img = Image.open(img_path_or_url).convert('RGB')\n",
        "\n",
        "        img = img.resize((input_shape[1], input_shape[0]))\n",
        "        img_array = image.img_to_array(img)\n",
        "\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        img_array = img_array / 255.0\n",
        "\n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar a imagem: {e}\")\n",
        "        return None\n",
        "\n",
        "def predict_image(img_path_or_url):\n",
        "    img_array = load_and_preprocess_image(img_path_or_url)\n",
        "\n",
        "    if img_array is None:\n",
        "        return\n",
        "\n",
        "    #Prediction\n",
        "    try:\n",
        "        prediction = model.predict(img_array)\n",
        "\n",
        "        dog_confidence = prediction[0][0] * 100\n",
        "        wolf_confidence = (1 - prediction[0][0]) * 100\n",
        "\n",
        "        predicted_class = 0 if dog_confidence > wolf_confidence else 1\n",
        "        label = 'dog' if predicted_class == 0 else 'wolf'\n",
        "\n",
        "        plt.imshow(img_array[0])\n",
        "        plt.title(f\"Predicted: {label}\\nDog: {dog_confidence:.2f}%, Wolf: {wolf_confidence:.2f}%\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao fazer a previsão: {e}\")\n",
        "\n",
        "#Example:\n",
        "img_path = '/kaggle/input/testes/cao3.jfif'  #Replace with the path or URL of the image you want to test\n",
        "predict_image(img_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 503285,
          "sourceId": 931379,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5870231,
          "sourceId": 9625199,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30055,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}